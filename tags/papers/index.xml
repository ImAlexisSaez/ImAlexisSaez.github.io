<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Papers | Infinitos Contrastes</title>
    <link>https://imalexissaez.github.io/tags/papers/</link>
      <atom:link href="https://imalexissaez.github.io/tags/papers/index.xml" rel="self" type="application/rss+xml" />
    <description>Papers</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Alexis Sáez ©2020</copyright><lastBuildDate>Thu, 23 Aug 2018 05:59:39 +0200</lastBuildDate>
    <image>
      <url>https://imalexissaez.github.io/img/sharing.jpg</url>
      <title>Papers</title>
      <link>https://imalexissaez.github.io/tags/papers/</link>
    </image>
    
    <item>
      <title>Porqué la mayoría de los resultados en investigación son falsos</title>
      <link>https://imalexissaez.github.io/2018/08/23/porque-la-mayoria-de-los-resultados-en-investigacion-son-falsos/</link>
      <pubDate>Thu, 23 Aug 2018 05:59:39 +0200</pubDate>
      <guid>https://imalexissaez.github.io/2018/08/23/porque-la-mayoria-de-los-resultados-en-investigacion-son-falsos/</guid>
      <description>&lt;p&gt;Cuanto menos, es ciertamente llamativo, así como invita con fuerza a su lectura, el título de uno de los artículos de &lt;em&gt;John P. A. Ioannidis&lt;/em&gt;: &amp;ldquo;&lt;em&gt;Why Most Published Research Findings Are False&lt;/em&gt;&amp;quot;.&lt;/p&gt;
&lt;p&gt;Estaba echando un vistazo a los contenidos de la primera semana del &lt;em&gt;MOOC&lt;/em&gt; &amp;ldquo;&lt;em&gt;Improving your statistical inferences&lt;/em&gt;&amp;rdquo; (
&lt;a href=&#34;https://www.coursera.org/learn/statistical-inferences&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;enlace&lt;/a&gt;), disponible en la plataforma &lt;em&gt;Coursera&lt;/em&gt; (curso que, por cierto, me ha dejado muy buenas sensaciones), y en uno de sus vídeos recomiendan la lectura del mencionado artículo.&lt;/p&gt;
&lt;p&gt;Por fortuna, es un texto de acceso abierto que podemos encontrar en este 
&lt;a href=&#34;http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;enlace&lt;/a&gt;. Tras la introducción técnica, la sección de corolarios no tiene desperdicio alguno. En ella se afirma que es menos probable que los resultados de la investigación en una disciplina científica sean verdaderos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cuanto menor sea el tamaño muestral.&lt;/li&gt;
&lt;li&gt;Cuanto menor sea el tamaño del efecto.&lt;/li&gt;
&lt;li&gt;Cuanto mayor sea el número de relaciones y menor sea el conjunto de las que están probadas.&lt;/li&gt;
&lt;li&gt;Cuanto mayor sean la flexibilidad en el diseño, las definiciones, los resultados y los modos de análisis.&lt;/li&gt;
&lt;li&gt;Cuanto mayor sean la financiación y otros intereses y prejuicios.&lt;/li&gt;
&lt;li&gt;Cuanto mayor sea el número de equipos científicos involucrados.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Además, aunque encontramos los anteriores factores expuestos de manera separada, a menudo es cierto que unos poseen influencia sobre otros y pueden presentarse de forma simultánea. El autor finaliza el artículo exponiendo algunas directrices para mejorar la situación planteada.&lt;/p&gt;
&lt;p&gt;Merece la pena dedicar un poco de nuestro tiempo a la lectura y estudio de este texto.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Aprendiendo de la experiencia de Jacob Cohen</title>
      <link>https://imalexissaez.github.io/2018/08/21/aprendiendo-de-la-experiencia-de-jacob-cohen/</link>
      <pubDate>Tue, 21 Aug 2018 05:59:39 +0200</pubDate>
      <guid>https://imalexissaez.github.io/2018/08/21/aprendiendo-de-la-experiencia-de-jacob-cohen/</guid>
      <description>&lt;p&gt;Por recomendación, el otro día puse las manos sobre el artículo de &lt;em&gt;Jacob Cohen&lt;/em&gt;: &amp;ldquo;&lt;em&gt;Things I Have Learned (So Far)&lt;/em&gt;&amp;quot;, publicado originalmente en diciembre de 1990 en la revista &lt;em&gt;American Psychologist&lt;/em&gt;. Veamos qué impresiones me ha dejado su lectura.&lt;/p&gt;
&lt;p&gt;Es posible que, por su antigüedad, alguien pueda llegar a pensar que no merece demasiado la pena dedicarle tiempo a este texto, ¡nada más lejos de la realidad!&lt;/p&gt;
&lt;p&gt;El acceso al documento original (
&lt;a href=&#34;http://psycnet.apa.org/psycinfo/1991-11596-001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;enlace&lt;/a&gt;), desgraciadamente, implica un desembolso de aproximadamente doce dólares. No obstante, a través de una búsqueda rápida en &lt;em&gt;Google&lt;/em&gt; es fácil (y, posiblemente, ilegal) dar con él e, incluso, con una traducción al español, publicada en el año 1992 en la revista &lt;em&gt;Anales de Psicología&lt;/em&gt;. La pregunta natural aquí es, ¿por qué un artículo publicado hace más de dos décadas no ha sido liberado completamente?&lt;/p&gt;
&lt;p&gt;Algunas de las claves que comparte Jacob Cohen y me han parecido interesantes son:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;En la medida de nuestras posibilidades, debemos evitar el uso inconsciente de las famosas &amp;ldquo;&lt;em&gt;reglas de oro&lt;/em&gt;&amp;quot;, que suelen instaurar rígidos criterios universales. Por ejemplo, en lugar de calificar una muestra como pequeña porque su tamaño es menor que treinta, conviene que llevemos a cabo un análisis del poder estadístico del estudio, para decidir si el tamaño muestral es el idóneo para los objetivos que perseguimos.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;em&gt;Menos es más&lt;/em&gt;&amp;rdquo; (salvo cuando hablamos de tamaños muestrales). No es demasiado recomendable que nuestros proyectos se caractericen por tener un número desproporcionado de variables dependientes, o independientes, o de ambos tipos. En esos casos, la cantidad de hipótesis a contrastar crece desmesuradamente, y deberíamos estar muy atentos al control del &lt;em&gt;error de tipo I&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;En relación con lo anterior, es aconsejable que prestemos atención también a la forma de presentar resultados. Los programas informáticos de hoy en día son capaces de arrojar cifras con un alto número de decimales, pero debemos detenernos a pensar hasta qué punto es útil reportarlos todos.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;em&gt;Simple es mejor&lt;/em&gt;&amp;quot;. Conviene que describamos gráficamente una variable antes que optar por hacerlo vía sus primeros momentos, así como que utilicemos un diagrama de puntos en lugar de escoger un indicador numérico para transmitir en qué medida están asociadas dos variables.&lt;/li&gt;
&lt;li&gt;Que podamos realizar, de manera sencilla, complejos análisis de datos utilizando programas informáticos, no implica que no sea necesario entender perfectamente qué estamos haciendo en cada momento del proceso.&lt;/li&gt;
&lt;li&gt;Conviene que nos detengamos a estudiar con detalle todo lo relacionado con la correcta interpretación del &lt;em&gt;p&lt;/em&gt;-valor (&amp;quot;&lt;em&gt;this result does not tell us about the truth of the null hypothesis, given the data […] What it tells us is the probability of the data, given the truth of the null hypothesis.&lt;/em&gt;&amp;quot;).&lt;/li&gt;
&lt;li&gt;Continuando con el punto anterior, no tenemos que utilizar el &lt;em&gt;p&lt;/em&gt;-valor como sustituto de un indicador del tamaño del efecto, y es recomendable que reportemos un intervalo de confianza de este último (de hecho, debería ser el principal objetivo de cualquier investigación) en la sección de resultados, para que los hallazgos significativos queden correctamente contextualizados.&lt;/li&gt;
&lt;li&gt;Conviene, antes de llevar a cabo cualquier estudio, que planeemos con atención el tamaño del efecto que buscamos, el nivel de significación que vamos a asumir y el poder estadístico con el que queremos trabajar. A partir de ellos, obtendremos el tamaño muestral necesario y, en el caso de encontrarse éste fuera de nuestras posibilidades, procederemos a realizar ajustes en las anteriores cantidades.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Por otra parte, algunas de las citas que me han encantado del artículo son:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;I have so heavily emphasized the desirability of working with few variables and large sample sizes that some of my students have spread the rumor that my idea of the perfect study is one with 10,000 cases and no variables. They go too far.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;We sometimes learn more from what we see than from what we compute; sometimes what we learn from what we see is that we shouldn’t compute, at least not on those data as they stand.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;The atmosphere that characterizes statistics as applied in the social and biomedical sciences is that of a secular religion (Salsburg, 1985), apparently of Judeo-Christian derivation, as it employs as its most powerful icon a six-pointed cross, often presented multiply for enhanced authority. I confess that I am an agnostic.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Despite widespread misconceptions to the contrary, the rejection of a given null hypothesis gives us no basis for estimating the probability that a replication of the research will again result in rejecting that null hypothesis.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;consider the sanctified (and sanctifying) magic .05 level. […] Its arbitrary unreasonable tyranny has led to data fudging of varying degrees of subtlety from grossly altering data to dropping cases where there &amp;lsquo;must have been&amp;rsquo; errors.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;I have learned and taught that the primary product of a research inquiry is one or more measures of effect size, not &lt;em&gt;p&lt;/em&gt; values.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;En resumen, una amena lectura aderezada de píldoras de sabiduría que recomendaría a cualquier persona interesada en esta disciplina.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Los 34 grados de libertad de un estudio</title>
      <link>https://imalexissaez.github.io/2018/08/02/los-34-grados-de-libertad-de-un-estudio/</link>
      <pubDate>Thu, 02 Aug 2018 05:59:39 +0200</pubDate>
      <guid>https://imalexissaez.github.io/2018/08/02/los-34-grados-de-libertad-de-un-estudio/</guid>
      <description>&lt;p&gt;Hace unos días, completé la lectura del estupendo artículo &lt;em&gt;&amp;ldquo;Degrees of freedom in planning, running, analyzing, and reporting psychological studies. A checklist to avoid p-hacking&amp;rdquo;&lt;/em&gt;, cuya lista de autores es casi tan extensa como el propio título, y de acceso abierto a través de 
&lt;a href=&#34;http://journal.frontiersin.org/article/10.3389/fpsyg.2016.01832/abstract&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;este enlace&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;En la línea de la famosa idea conocida como &lt;em&gt;&amp;ldquo;The Garden of Forking Paths&amp;rdquo;&lt;/em&gt;, acuñada por &lt;em&gt;Andrew Gelman&lt;/em&gt;, el mencionado documento lista los múltiples grados de libertad existentes en todas y cada una de las fases de un estudio. Ahora bien, ¿a qué nos referimos cuando hablamos de los grados de libertad de un estudio?&lt;/p&gt;
&lt;p&gt;Sin entrar aquí en demasiado detalle, se trata de ciertas decisiones arbitrarias (intencionadas o no) que los investigadores toman en sus investigaciones a la hora de diseñarlas, recoger los datos de interés, analizar éstos y posteriormente reportarlos en publicaciones científicas. Es lógico entonces que nos planteemos la siguiente cuestión: ¿qué efecto poseen los grados de libertad de un estudio sobre las conclusiones alcanzadas?&lt;/p&gt;
&lt;p&gt;Entre otras, las dos principales consecuencias son, por un lado, el incremento de la probabilidad de hallar resultados que no son más que falsos positivos, y, por otra parte, la posibilidad de inflar las estimaciones para los tamaños de los efectos observados. Así pues, ¿es posible evitar su aparición en un estudio?&lt;/p&gt;
&lt;p&gt;A día de hoy, el mejor método (aunque dista de ser perfecto) para que un estudio esté libre de grados de libertad es utilizar, de manera precisa y muy detallada, un recurso conocido como &lt;em&gt;pre-registro&lt;/em&gt; (&lt;em&gt;preregistration&lt;/em&gt; en inglés). La idea es presentar, e incluso someter a revisión de pares, el plan que seguirá cierta investigación antes de realizar la propia recolección de los datos de interés.&lt;/p&gt;
&lt;p&gt;En el citado artículo se ofrece un listado (no totalmente exhaustivo) de los grados de libertad que puede presentar un estudio, restringiendo este al marco de referencia habitual utilizado para el contraste de hipótesis. De esta forma, los autores advierten que habría que eliminar o añadir ciertos grados de libertad si es otra la metodología empleada.&lt;/p&gt;
&lt;p&gt;Algunos de los mencionados grados de libertad están relacionados entre sí (recomiendo consultar la tabla que figura en la última página del artículo) o incluso pueden llegar a dar la impresión de aparecer por duplicado. No obstante, se justifica este hecho por la importancia de adoptar cierta decisión en una fase del estudio u otra.&lt;/p&gt;
&lt;p&gt;A modo de resumen, estos son los 34 grados de libertad de un estudio, desglosados en función de las distintas etapas de una investigación:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Fase de generación de hipótesis&lt;/em&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;[T1]&lt;/em&gt; Llevar a cabo investigaciones exploratorias. Esto conduce a una práctica conocida como &lt;em&gt;&amp;ldquo;HARKing&amp;rdquo;&lt;/em&gt; (&lt;em&gt;&amp;ldquo;Hypothesizing After Results are Known&amp;rdquo;&lt;/em&gt;, que vendría a ser generar hipótesis una vez se conocen los resultados).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[T2]&lt;/em&gt; Declarar hipótesis imprecisas que no indiquen la dirección del posible efecto. Es un tipo especial de &lt;em&gt;&amp;ldquo;HARKing&amp;rdquo;&lt;/em&gt;, ya que el investigador puede luego analizar los datos de dos maneras alternativas.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Fase de diseño&lt;/em&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;[D1]&lt;/em&gt; Crear múltiples condiciones y variables independientes manipuladas. A medida que el diseño de un estudio adquiere complejidad, esta práctica puede conducir a posibles futuras decisiones con respecto a los niveles de las variables que se están considerando o sobre las condiciones en la que centra el foco de atención.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[D2]&lt;/em&gt; Medir variables adicionales sin decidir de antemano si éstas serán bien covariables, bien variables independientes, bien variables mediadoras, o bien variables moderadoras.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[D3]&lt;/em&gt; Registrar la misma variable dependiente de diferentes formas alternativas. Esta práctica puede tentar al investigador a adoptar al final la escala que favorezca la aparición de resultados significativos.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[D4]&lt;/em&gt; Medir variables dependientes (o incluso probar teorías) adicionales, diseñadas en principio como secundarias en el estudio, que luego adopten un rol primario en los resultados del estudio si las variables principales fallan a la hora de mostrar efecto alguno (esto podría considerarse también como una especie de &lt;em&gt;&amp;ldquo;HARKing&amp;rdquo;&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[D5]&lt;/em&gt; Incorporar variables adicionales que permitan, &lt;em&gt;a posteriori&lt;/em&gt;, al investigador, la exclusión del análisis de ciertos (o incluso grupos de) participantes, con el propósito de encontrar así resultados significativos.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[D6]&lt;/em&gt; No realizar un análisis del poder estadístico del estudio. Es más, el investigador suele adoptar una posición extremadamente optimista al respecto de este asunto cuando trabaja con muestras pequeñas, lo cual se traduce en estudios de bajo poder estadístico.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[D7]&lt;/em&gt; No informar acerca del plan de muestreo, permitiendo así la posibilidad de realizar, de manera consecutiva, múltiples pequeños estudios hasta dar con el resultado significativo deseado (y sin haber controlado el efecto que esta práctica posee sobre el &lt;em&gt;error de tipo I&lt;/em&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Fase de recolección de datos&lt;/em&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;[C1]&lt;/em&gt; No asignar los participantes de un estudio a las condiciones de forma aleatoria, lo cual da lugar a la posible aparición de variables de confusión.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[C2]&lt;/em&gt; No escoger de manera acertada la técnica de enmascaramiento (simple, doble o triple ciego), bien para los participantes, bien para los investigadores, pudiendo sesgar así los resultados del estudio.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[C3]&lt;/em&gt; Corregir, codificar o descartar datos durante la fase de recolección, de una forma no coherente con la técnica de enmascaramiento asociada al estudio.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[C4]&lt;/em&gt; Determinar la regla de parada de recolección de datos en función de si se ha obtenido, o no, el resultado deseado.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Fase de análisis&lt;/em&gt;: los puntos que se listan a continuación en este apartado son una serie de decisiones con marcado carácter 
&lt;a href=&#34;https://es.wikipedia.org/wiki/Ad_hoc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;ad hoc&lt;/em&gt;&lt;/a&gt; por parte del investigador.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;[A1]&lt;/em&gt; Seleccionar entre diferentes opciones de tratamiento para los datos incompletos o perdidos.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A2]&lt;/em&gt; Especificar el pre-procesamiento de los datos (limpieza, normalización, suavizado o correcciones).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A3]&lt;/em&gt; Dictaminar cómo lidiar con las violaciones de los supuestos estadísticos.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A4]&lt;/em&gt; Decidir cómo tratar con los valores atípicos.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A5]&lt;/em&gt; Determinar la variable dependiente de entre las múltiples alternativas existentes asociadas a una misma teoría.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A6]&lt;/em&gt; Probar diferentes maneras de anotar o registrar (o emplear distintas escalas para) una variable dependiente.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A7]&lt;/em&gt; Optar por una teoría alternativa como principal resultado.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A8]&lt;/em&gt; Escoger las variables independientes de entre un conjunto de variables independientes manipuladas.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A9]&lt;/em&gt; Usar las variables independientes manipuladas de diversas formas.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A10]&lt;/em&gt; Incluir diferentes variables probándolas bien como covariables, bien como variables independientes, bien como variables mediadoras, bien como variables moderadoras.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A11]&lt;/em&gt; Utilizar las variables independientes no manipuladas de distintas maneras.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A12]&lt;/em&gt; Usar un criterio alternativo de inclusión y exclusión de participantes.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A13]&lt;/em&gt; La propia determinación del modelo estadístico.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A14]&lt;/em&gt; La elección del método de estimación, el programa informático donde se va a llevar a cabo el análisis de datos, y la forma en la que se calculan los errores estándar.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[A15]&lt;/em&gt; La elección del criterio de inferencia.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Fase de informe&lt;/em&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;[R1]&lt;/em&gt; No asegurar la reproducibilidad del estudio.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[R2]&lt;/em&gt; No habilitar (o facilitar la posibilidad de) la replicación del estudio.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[R3]&lt;/em&gt; Para los estudios que han sido pre-registrados, no mencionar, falsificar o identificar erróneamente su pre-registro.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[R4]&lt;/em&gt; No informar de los denominados &amp;ldquo;estudios fallidos&amp;rdquo; que fueron originalmente considerados relevantes para la investigación propuesta.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[R5]&lt;/em&gt; No informar adecuadamente de los resultados y los &lt;em&gt;p&lt;/em&gt;-valores.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;[R6]&lt;/em&gt; Formular hipótesis después de observar los resultados (el ya nombrado &lt;em&gt;&amp;ldquo;HARKing&amp;rdquo;&lt;/em&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Los autores dedican en el artículo, a cada uno de los anteriores 34 puntos, algunos párrafos para contextualizarlos, explicar su influencia sobre los resultados y ofrecer buenas prácticas para evitar que hagan acto de presencia en el estudio.&lt;/p&gt;
&lt;p&gt;En resumen, una lectura que merece la pena y que recomiendo encarecidamente.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
